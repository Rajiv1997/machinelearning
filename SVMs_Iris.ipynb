{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "SVMs-Iris.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kanacb/machinelearning/blob/main/SVMs_Iris.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L45GNF5RVQ5Y"
      },
      "source": [
        "# Import software libraries and load the dataset #"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yewe5GG6VQ5f"
      },
      "source": [
        "import sys                             # Read system parameters.\n",
        "import numpy as np                     # Work with multi-dimensional arrays and matrices.\n",
        "import pandas as pd                    # Manipulate and analyze data.\n",
        "import matplotlib as mpl               # Create 2D charts.\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb                   # Perform data visualization.\n",
        "import sklearn                         # Perform data mining and analysis.\n",
        "from sklearn import datasets\n",
        "\n",
        "# Summarize software libraries used.\n",
        "print('Libraries used in this project:')\n",
        "print('- Python {}'.format(sys.version))\n",
        "print('- NumPy {}'.format(np.__version__))\n",
        "print('- pandas {}'.format(pd.__version__))\n",
        "print('- Matplotlib {}'.format(mpl.__version__))\n",
        "print('- scikit-learn {}\\n'.format(sklearn.__version__))\n",
        "\n",
        "# Load the dataset.\n",
        "iris = datasets.load_iris()\n",
        "print('Loaded {} records.'.format(len(iris.data)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsmO_A9cVQ5h"
      },
      "source": [
        "# Get acquainted with the dataset #"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bjk54g5-VQ5i"
      },
      "source": [
        "# Convert array to pandas DataFrame.\n",
        "data_raw = pd.DataFrame(iris['data'], columns = iris['feature_names'])\n",
        "data_raw['target'] = iris['target']\n",
        "\n",
        "print(data_raw.info())      # View data types and see if there are missing entries.\n",
        "data_raw.head(10)           # View first 10 records."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFQZOhfxVQ5i"
      },
      "source": [
        "# Examine a general summary of statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhNwG7sUVQ5j"
      },
      "source": [
        "with pd.option_context('float_format', '{:.2f}'.format): \n",
        "    print(data_raw.describe())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2A5U1wHVQ5j"
      },
      "source": [
        "# Identify outliers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGsrGWgcVQ5k"
      },
      "source": [
        "plt.figure(figsize = (20, 2))\n",
        "bplot = sb.boxplot(x = 'sepal width (cm)', data = data_raw, orient = 'h', fliersize = 7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-qfceWAVQ5l"
      },
      "source": [
        "# Reduce the dimensionality of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pABQGiutVQ5m"
      },
      "source": [
        "X = iris['data'][:, :2]  # Only use first two features (sepal length and sepal width).\n",
        "y = iris['target']\n",
        "\n",
        "print(\"\\nBefore reduction:\")\n",
        "print(\"X dataset dimensions are\", X.shape)\n",
        "print(\"y dataset dimensions are\", y.shape)\n",
        "\n",
        "# Only use labels 0 and 1 (setosa and versicolor).\n",
        "class_labels = (y == 0) | (y == 1)\n",
        "X = X[class_labels]\n",
        "y = y[class_labels]\n",
        "\n",
        "print(\"\\nAfter reduction:\")\n",
        "print(\"X dataset dimensions are\", X.shape)\n",
        "print(\"y dataset dimensions are\", y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69WJ027dVQ5n"
      },
      "source": [
        "# Examine the separation between classes using a scatter plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbRDKAmeVQ5o"
      },
      "source": [
        "# Sepal length along x-axis, sepal width along y-axis.\n",
        "scatter_x = X[:, 0]\n",
        "scatter_y = X[:, 1]\n",
        "\n",
        "cdict = {0: 'green', 1: 'grey'}\n",
        "\n",
        "# Generate scatter plot with legend.\n",
        "for c_label in np.unique(y):\n",
        "    if c_label == 0:\n",
        "        iris = 'setosa'\n",
        "    if c_label == 1:\n",
        "        iris = 'versicolor'\n",
        "    \n",
        "    ix = np.where(y == c_label)\n",
        "    plt.scatter(scatter_x[ix], scatter_y[ix], c = cdict[c_label], label = iris, s = 40)\n",
        "    \n",
        "plt.legend()\n",
        "plt.xlabel(\"Sepal length\", fontsize = 13)\n",
        "plt.ylabel(\"Sepal width\", fontsize = 13)\n",
        "plt.annotate('Possible outlier', xy = (4.4, 2.3), xytext = (2.9, 2.2),\n",
        "             arrowprops = dict(color= 'black'), fontsize = 15);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2QXkHqrVQ5p"
      },
      "source": [
        "# Plot a decision boundary for a given model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqtGt-A-VQ5r"
      },
      "source": [
        "def plot_decision_boundary(X, y, model, is_svm):\n",
        "    scatter_x = X[:, 0]\n",
        "    scatter_y = X[:, 1]\n",
        "\n",
        "    cdict = {0: 'green', 1: 'grey'}\n",
        "\n",
        "    for c_label in np.unique(y):\n",
        "        if c_label == 0:\n",
        "            iris = 'setosa'\n",
        "        if c_label == 1:\n",
        "            iris = 'versicolor'\n",
        "\n",
        "        ix = np.where(y == c_label)\n",
        "        plt.scatter(scatter_x[ix], scatter_y[ix], c = cdict[c_label], label = iris, s = 40)\n",
        "        \n",
        "    plt.legend()\n",
        "    plt.xlabel(\"Sepal length\", fontsize = 13)\n",
        "    plt.ylabel(\"Sepal width\", fontsize = 13)\n",
        "\n",
        "    ax = plt.gca()\n",
        "    xlim = ax.get_xlim()\n",
        "    ylim = ax.get_ylim()\n",
        "\n",
        "    # Create grid.\n",
        "    xx = np.linspace(xlim[0], xlim[1], 40)\n",
        "    yy = np.linspace(ylim[0], ylim[1], 40)\n",
        "    YY, XX = np.meshgrid(yy, xx)\n",
        "    xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
        "    Z = model.decision_function(xy).reshape(XX.shape)  # Use model decision function to plot boundary.\n",
        "    \n",
        "    if is_svm == True:\n",
        "        # Plot decision boundary and margins.\n",
        "        ax.contour(XX, YY, Z, colors = 'r', levels = [-1, 0, 1], \n",
        "                   linestyles=['--', '-', '--'])\n",
        "        \n",
        "        # Plot support vectors.\n",
        "        ax.scatter(model.support_vectors_[:, 0], model.support_vectors_[:, 1],\n",
        "                   s = 100, linewidth = 1, facecolors = 'none', edgecolors = 'k')\n",
        "    else:\n",
        "        ax.contour(XX, YY, Z, colors = 'r', levels = [0], \n",
        "                   linestyles=['-'])\n",
        "        \n",
        "    plt.show()\n",
        "    \n",
        "print('Function to plot the decision boundary has been defined.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCxhaJpiVQ5s"
      },
      "source": [
        "# Train a basic logistic regression model and plot its decision boundary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwYlu0PjVQ5t"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "log_reg = LogisticRegression(solver = 'liblinear', random_state = 1936)\n",
        "log_reg.fit(X, y);\n",
        "\n",
        "plot_decision_boundary(X, y, log_reg, False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEAOIGjXVQ5t"
      },
      "source": [
        "# Train an SVM model and plot its decision boundary plus margins"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWaVPNHpVQ5t"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svm = SVC(kernel = 'linear', C = 100, random_state = 1936)\n",
        "svm.fit(X, y)\n",
        "\n",
        "plot_decision_boundary(X, y, svm, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LAQfG-nVQ5u"
      },
      "source": [
        "# Reduce the regularization penalty to soften the margin"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23qKJIF9VQ5u"
      },
      "source": [
        "svm = SVC(kernel = 'linear', C = 0.1, random_state = 1936)\n",
        "svm.fit(X, y)\n",
        "\n",
        "plot_decision_boundary(X, y, svm, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECR8QAwVVQ5v"
      },
      "source": [
        "# Split the datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NZy4UTRVQ5v"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "label_columns = ['target']\n",
        "\n",
        "training_columns = ['sepal length (cm)', 'sepal width (cm)' , 'petal length (cm)', 'petal width (cm)']\n",
        "\n",
        "# Split the training and test datasets and their labels.\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_raw[training_columns],\n",
        "                                                                            data_raw[label_columns],\n",
        "                                                                            random_state = 1936)\n",
        "\n",
        "print('The training and test datasets and their labels have been split.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciHWsy_aVQ5w"
      },
      "source": [
        "# Evaluate an SVM model using a holdout test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8TNXU07VQ5w"
      },
      "source": [
        "svm = SVC(kernel = 'linear', C = 100, random_state = 1936)\n",
        "svm.fit(X_train, np.ravel(y_train))\n",
        "\n",
        "# Score using the test data.\n",
        "score = svm.score(X_test, y_test)\n",
        "\n",
        "print('Accuracy: {:.0f}%'.format(score * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4qKeapfVQ5w"
      },
      "source": [
        "# Optimize the SVM model with grid search and cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNe-wNhmVQ5x"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "svm = SVC(gamma = 'auto', random_state = 1936)\n",
        "\n",
        "grid = [{'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
        "         'C': [0.01, 0.1, 1, 5, 10, 25, 50, 100]}]\n",
        "\n",
        "search = GridSearchCV(svm, param_grid = grid, scoring = 'accuracy', cv = 5, iid = False)\n",
        "search.fit(X_train, np.ravel(y_train));\n",
        "\n",
        "print(search.best_params_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DB-ed3A0VQ5x"
      },
      "source": [
        "# Score using the test data.\n",
        "score = search.score(X_test, y_test)\n",
        "\n",
        "print('Accuracy: {:.0f}%'.format(score * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBObSoOqVQ5x"
      },
      "source": [
        "# Examine the optimized SVM model's predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7VOEW_XVQ5x"
      },
      "source": [
        "# Use test set to evaluate.\n",
        "results_comparison = X_test.copy()\n",
        "results_comparison['Predicted Iris'] = search.predict(X_test)\n",
        "results_comparison['Actual Iris'] = y_test.copy()\n",
        "\n",
        "# Map labels to actual Iris names.\n",
        "iris_encode = {0: 'setosa', 1: 'versicolor', 2: 'virginica'}\n",
        "    \n",
        "results_comparison['Predicted Iris'] = results_comparison['Predicted Iris'].map(iris_encode)\n",
        "results_comparison['Actual Iris'] = results_comparison['Actual Iris'].map(iris_encode)\n",
        "\n",
        "# View examples of the predictions compared to actual Iris.\n",
        "results_comparison.head(20)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}