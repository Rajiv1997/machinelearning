{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "RandomForests-Titanic.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kanacb/machinelearning/blob/main/RandomForests_Titanic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CKEkaC7gEGK"
      },
      "source": [
        "# Import software libraries and load the dataset #"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfDUsKgrgEGR"
      },
      "source": [
        "import sys                             # Read system parameters.\n",
        "import os                              # Interact with the operating system.\n",
        "import numpy as np                     # Work with multi-dimensional arrays and matrices.\n",
        "import pandas as pd                    # Manipulate and analyze data.\n",
        "import matplotlib                      # Create 2D charts.\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb                   # Perform data visualization.\n",
        "import sklearn                         # Perform data mining and analysis.\n",
        "from time import time                  # Calculate training time.\n",
        "\n",
        "# Summarize software libraries used.\n",
        "print('Libraries used in this project:')\n",
        "print('- Python {}'.format(sys.version))\n",
        "print('- NumPy {}'.format(np.__version__))\n",
        "print('- pandas {}'.format(pd.__version__))\n",
        "print('- Matplotlib {}'.format(matplotlib.__version__))\n",
        "print('- Seaborn {}'.format(sb.__version__))\n",
        "print('- scikit-learn {}\\n'.format(sklearn.__version__))\n",
        "\n",
        "# Load the dataset.\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "DATA_PATH = os.path.join(PROJECT_ROOT_DIR, \"titanic_data\")\n",
        "print('Data files in this project:', os.listdir(DATA_PATH))\n",
        "data_raw_file = os.path.join(DATA_PATH, 'train.csv')\n",
        "data_raw = pd.read_csv(data_raw_file)\n",
        "print('Loaded {} records from {}.'.format(len(data_raw), data_raw_file))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8kEpNZ0gEGU"
      },
      "source": [
        "# Split the datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POCTpHLrgEGV"
      },
      "source": [
        "# Separate training and test sets already exist.\n",
        "# A validation set will be split off from the training sets.\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 'Survived' is the dependent variable (value to be predicted), so it will be\n",
        "# removed from the training data and put into a separate DataFrame for labels.\n",
        "label_columns = ['Survived']\n",
        "\n",
        "training_columns = ['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n",
        "\n",
        "# Split the training and validation datasets and their labels.\n",
        "X_train, X_val, y_train, y_val = train_test_split(data_raw[training_columns],\n",
        "                                                                            data_raw[label_columns],\n",
        "                                                                            random_state = 1912)\n",
        "\n",
        "print('The datasets and labels have been split.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YCssBhfgEGW"
      },
      "source": [
        "# Perform common preparation on the training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfetOU0SgEGX"
      },
      "source": [
        "# Perform common cleaning and feature engineering tasks on datasets.\n",
        "def prep_dataset(dataset):\n",
        "    \n",
        "    # PROVIDE MISSING VALUES\n",
        "    \n",
        "    # Fill missing Age values with the median age.\n",
        "    dataset['Age'].fillna(dataset['Age'].median(), inplace = True)\n",
        "\n",
        "    # Fill missing Fare values with the median fare.\n",
        "    dataset['Fare'].fillna(dataset['Fare'].median(), inplace = True)\n",
        "\n",
        "    # Fill missing Embarked values with the mode.\n",
        "    dataset['Embarked'].fillna(dataset['Embarked'].mode()[0], inplace = True)\n",
        "    \n",
        "    # ONE-HOT ENCODING\n",
        "    \n",
        "    cols = ['Pclass', 'Sex', 'Embarked']\n",
        "    \n",
        "    for i in cols:\n",
        "        dummies = pd.get_dummies(dataset[i], prefix = i, drop_first = False)\n",
        "        dataset = pd.concat([dataset, dummies], axis = 1)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "X_train = prep_dataset(X_train.copy())\n",
        "\n",
        "X_val = prep_dataset(X_val.copy())\n",
        "\n",
        "print('The datasets have been cleaned and prepared.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzvSIMhogEGZ"
      },
      "source": [
        "# Drop columns that won't be used for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKWPd5FdgEGa"
      },
      "source": [
        "# Drop unused columns from datasets.\n",
        "def drop_unused(dataset):\n",
        "        \n",
        "    dataset = dataset.drop(['PassengerId'], axis = 1)\n",
        "    dataset = dataset.drop(['Cabin'], axis = 1)\n",
        "    dataset = dataset.drop(['Ticket'], axis = 1)\n",
        "    dataset = dataset.drop(['Name'], axis = 1)\n",
        "\n",
        "    # These have been replaced with one-hot encoding.\n",
        "    dataset = dataset.drop(['Pclass'], axis = 1)\n",
        "    dataset = dataset.drop(['Sex'], axis = 1)\n",
        "    dataset = dataset.drop(['Embarked'], axis = 1)\n",
        "    \n",
        "    return dataset\n",
        "\n",
        "X_train = drop_unused(X_train.copy())\n",
        "\n",
        "X_val = drop_unused(X_val.copy())\n",
        "\n",
        "print('Unused columns have been dropped.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qpdo8KYfgEGb"
      },
      "source": [
        "# Create a random forest model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBqL4XVGgEGc"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "forest = RandomForestClassifier(n_estimators = 100,\n",
        "                                criterion = 'gini',\n",
        "                                max_depth = 6,\n",
        "                                min_samples_leaf = 10,\n",
        "                                min_samples_split = 78,\n",
        "                                bootstrap = True,\n",
        "                                oob_score = True,\n",
        "                                random_state = 1912)\n",
        "\n",
        "forest.fit(X_train, np.ravel(y_train))\n",
        "\n",
        "prediction = forest.predict(X_val)\n",
        "\n",
        "# Score using the validation data.\n",
        "score = forest.score(X_val, y_val)\n",
        "\n",
        "print('Accuracy: {:.0f}%'.format(score * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWVi64LqgEGc"
      },
      "source": [
        "# Visualize the structure of one decision tree in the forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sw6m46fGgEGd"
      },
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "from sklearn.externals.six import StringIO  \n",
        "from IPython.display import Image, display \n",
        "import pydotplus as pdotp\n",
        "\n",
        "def plot_tree(model, image):\n",
        "    dot_data = StringIO()\n",
        "    export_graphviz(model, out_file = dot_data, \n",
        "                    filled = True,\n",
        "                    rounded = True,\n",
        "                    special_characters = True, \n",
        "                    feature_names = X_train.columns.values.tolist(),\n",
        "                    class_names = ['0', '1'])\n",
        "\n",
        "    graph = pdotp.graph_from_dot_data(dot_data.getvalue())  \n",
        "    graph.write_png(image)\n",
        "    Image(graph.create_png())\n",
        "    \n",
        "print('The visualization function has been defined.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROJR1qfmgEGd"
      },
      "source": [
        "# Compute accuracy, precision, recall, and F<sub>1</sub> score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVO_7fXbgEGd"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def model_scores(y, prediction):\n",
        "    acc = accuracy_score(y, prediction)\n",
        "    print('Accuracy: {:.0f}%'.format(np.round(acc * 100)))\n",
        "    \n",
        "    precision = precision_score(y, prediction)\n",
        "    print('Precision: {:.0f}%'.format(np.round(precision * 100)))\n",
        "    \n",
        "    recall = recall_score(y, prediction)\n",
        "    print('Recall: {:.0f}%'.format(np.round(recall * 100)))\n",
        "    \n",
        "    f1 = f1_score(y, prediction)\n",
        "    print('F1: {:.0f}%'.format(np.round(f1 * 100)))\n",
        "    \n",
        "print('The function to show the scores has been defined.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12TA1dDIgEGe"
      },
      "source": [
        "# Generate a ROC curve and compute the AUC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLQfE7t9gEGe"
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def roc(y, prediction_proba):\n",
        "    fpr, tpr, thresholds = roc_curve(y, prediction_proba)\n",
        "    \n",
        "    plt.plot(fpr, tpr);\n",
        "    plt.xlim([0.0, 1.0]);\n",
        "    plt.ylim([0.0, 1.0]);\n",
        "    plt.title('ROC Curve');\n",
        "    plt.xlabel('False Positive Rate');\n",
        "    plt.ylabel('True Positive Rate');\n",
        "    plt.grid(True);\n",
        "    \n",
        "    auc = roc_auc_score(y, prediction_proba)\n",
        "    print('Area Under Curve: {:.2f}'.format(auc))\n",
        "    \n",
        "print('The function to generate the ROC curve and compute AUC has been defined.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNuLP-CDgEGf"
      },
      "source": [
        "# Generate a precision–recall curve and compute the average precision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3XgOjFUgEGf"
      },
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "def prc(y, prediction_proba):\n",
        "    precision, recall, thresholds = precision_recall_curve(y, prediction_proba)\n",
        "    \n",
        "    plt.plot(recall, precision);\n",
        "    plt.xlim([0.0, 1.0]);\n",
        "    plt.ylim([0.0, 1.0]);\n",
        "    plt.title('Precision–Recall Curve');\n",
        "    plt.xlabel('Recall');\n",
        "    plt.ylabel('Precision');\n",
        "    plt.grid(True);\n",
        "    \n",
        "    ap = average_precision_score(y, prediction_proba)\n",
        "    print('Average Precision: {:.2f}'.format(ap))\n",
        "    \n",
        "print('The function to generate a PRC and compute average precision has been defined.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-yAWmaLgEGg"
      },
      "source": [
        "# Examine a couple of trees in the forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvJXXVkGgEGg"
      },
      "source": [
        "plot_tree(forest.estimators_[0], 'titanic_forest_tree0.png')\n",
        "display(Image('titanic_forest_tree0.png'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KOB9MvGgEGh"
      },
      "source": [
        "plot_tree(forest.estimators_[1], 'titanic_forest_tree1.png')\n",
        "display(Image('titanic_forest_tree1.png'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXL3iwIMgEGh"
      },
      "source": [
        "# Evaluate the random forest model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbLWAHSHgEGh"
      },
      "source": [
        "model_scores(y_val, prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QXMelV6gEGh"
      },
      "source": [
        "predict_proba = forest.predict_proba(X_val)\n",
        "\n",
        "roc(y_val, predict_proba[:, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4llEZiWgEGh"
      },
      "source": [
        "prc(y_val, predict_proba[:, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_h0ThilvgEGi"
      },
      "source": [
        "# Generate the out-of-bag error and decision function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bIcKc4hgEGi"
      },
      "source": [
        "oob_error = 1 - forest.oob_score_\n",
        "print('Out-of-bag error: {}'.format(round(oob_error, 3)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPkMI7hqgEGi"
      },
      "source": [
        "forest.oob_decision_function_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVdo6x8ngEGi"
      },
      "source": [
        "# Verify that the random forest took the majority vote of all trees in the forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNUhe_IDgEGi"
      },
      "source": [
        "from statistics import mode\n",
        "\n",
        "class_list = []\n",
        "class_mode = []\n",
        "i = 0\n",
        "\n",
        "for i in range(10):  # Get predictions for the first 10 data examples.\n",
        "    for tree in forest.estimators_:  # Get predictions from all trees in forest.\n",
        "        predict = tree.predict(X_val)\n",
        "        predict_examples = predict[i]\n",
        "        class_list.append(predict_examples)\n",
        "\n",
        "    # Get mode of predictions to determine majority vote for each example.   \n",
        "    class_mode.append(int(mode(class_list)))\n",
        "    class_list = []\n",
        "\n",
        "print('Majority vote classification:    {}'.format(np.array(class_mode)))\n",
        "print('Random forest classification:    {}'.format(forest.predict(X_val)[0:10]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNoq81UogEGj"
      },
      "source": [
        "# Identify important features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Imm4ojCkgEGj"
      },
      "source": [
        "# Get feature importances.\n",
        "feature_importances = list(forest.feature_importances_)\n",
        "\n",
        "# Get column names.\n",
        "feature_list = list(X_train)\n",
        "\n",
        "importances_list = []\n",
        "\n",
        "# Map feature/importance indices and put into a single list.\n",
        "for feature, importance in zip(feature_list, feature_importances):\n",
        "    importances_list.append((feature, round(importance, 2)))\n",
        "\n",
        "# Sort list by importance index.\n",
        "importances_list = sorted(importances_list, key = lambda i: i[1], reverse = True)\n",
        "\n",
        "for feature, importance in importances_list:\n",
        "    print('Feature: {:10} | Importance: {}'.format(feature, importance))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv8oOncTgEGj"
      },
      "source": [
        "y_values = list(range(len(feature_importances)))\n",
        "plt.barh(y_values, feature_importances)\n",
        "plt.yticks(y_values, feature_list, rotation='horizontal')\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Features')\n",
        "plt.title('Feature Importances');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S46G3OfugEGj"
      },
      "source": [
        "# Select the most important features to use for a new round of training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbpWWUB3gEGj"
      },
      "source": [
        "X_train = X_train[['Sex_female', 'Sex_male', 'Pclass_3', 'Fare']].copy()\n",
        "X_val = X_val[['Sex_female', 'Sex_male', 'Pclass_3', 'Fare']].copy()\n",
        "\n",
        "X_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlvUThTPgEGj"
      },
      "source": [
        "# Train a new random forest model on the dataset with reduced dimensionality"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhF6BTyTgEGk"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "forest = RandomForestClassifier(n_estimators = 100,\n",
        "                                criterion = 'gini',\n",
        "                                max_depth = 6,\n",
        "                                min_samples_leaf = 10,\n",
        "                                min_samples_split = 78,\n",
        "                                bootstrap = True,\n",
        "                                oob_score = True,\n",
        "                                random_state = 1912)\n",
        "\n",
        "forest.fit(X_train, np.ravel(y_train))\n",
        "\n",
        "prediction = forest.predict(X_val)\n",
        "\n",
        "# Score using the validation data.\n",
        "score = forest.score(X_val, y_val)\n",
        "\n",
        "print('Accuracy: {:.0f}%'.format(score * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nce0SYcWgEGk"
      },
      "source": [
        "# Evaluate the new random forest model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IYiJ6oRgEGk"
      },
      "source": [
        "model_scores(y_val, prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JpZ4iXngEGk"
      },
      "source": [
        "predict_proba = forest.predict_proba(X_val)\n",
        "\n",
        "roc(y_val, predict_proba[:, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVFHJzSTgEGl"
      },
      "source": [
        "prc(y_val, predict_proba[:, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSxTU4qHgEGl"
      },
      "source": [
        "oob_error = 1 - forest.oob_score_\n",
        "print('Out-of-bag error: {}'.format(round(oob_error, 3)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzCfFEkSgEGl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}